import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import BertModel, BertTokenizer
from einops import rearrange
import numpy as np

class ClassicStateInitializer(nn.Module):
    """ç»å…¸æ€åˆå§‹åŒ–æ¨¡å—ï¼ˆBERTï¼‰: ğ“‘_init: ğ“£_text â†’ ğ“’"""
    
    def __init__(self, pretrained_model="bert-base-chinese", output_dim=768):
        super().__init__()
        self.bert = BertModel.from_pretrained(pretrained_model)
        self.output_dim = output_dim
        
        if output_dim != self.bert.config.hidden_size:
            self.projection = nn.Linear(self.bert.config.hidden_size, output_dim)
        else:
            self.projection = nn.Identity()
    
    def forward(self, text_input_ids, attention_mask=None):
        """
        æ˜ å°„: x â†’ ğ“‘ğ“”ğ“¡ğ“£(x) = Ïˆ_c^0
        """
        outputs = self.bert(input_ids=text_input_ids, attention_mask=attention_mask)
        cls_token = outputs.last_hidden_state[:, 0]  # å–[CLS]æ ‡è®°ä½œä¸ºå¥å­è¡¨ç¤º
        psi_c_0 = self.projection(cls_token)  # åˆå§‹ç»å…¸è¡¨ç¤º
        return psi_c_0

class ModalBridgeEncoder(nn.Module):
    """æ¨¡æ€æ¡¥æ¥ç¼–ç å™¨ H: ğ• â†’ ğ“’ âˆª ğ“ """
    
    def __init__(self, dim=768, img_dim=2048):
        super().__init__()
        self.dim = dim
        self.text_tokenizer = BertTokenizer.from_pretrained("bert-base-chinese")
        self.text_encoder = ClassicStateInitializer()
        self.img_encoder = nn.Sequential(
            nn.Linear(img_dim, dim*2),
            nn.ReLU(),
            nn.Linear(dim*2, dim)
        )
    
    def forward(self, x, modality='text'):
        """
        ç»Ÿä¸€æ¨¡æ€ç¼–ç å‡½æ•°:
        H: ğ• â†’ ğ“’ âˆª ğ“ 
        """
        if modality == 'text':
            if isinstance(x, str):
                inputs = self.text_tokenizer(x, return_tensors="pt")
                return self.text_encoder(inputs.input_ids, inputs.attention_mask)
            else:
                return self.text_encoder(x['input_ids'], x['attention_mask'])
        elif modality == 'image':
            return self.img_encoder(x)
        elif modality == 'numeric':
            return torch.sign(x)  # sign(x) for numeric data
        else:
            raise ValueError(f"Unsupported modality: {modality}")

class ExtendedMRAO(nn.Module):
    """æ‰©å±•MRAOè½¨è¿¹ç®—å­: MRAO*"""
    
    def __init__(self, dim=768, window_size=5, gamma=0.85):
        super().__init__()
        self.dim = dim
        self.window_size = window_size
        self.gamma = gamma
        self.register_buffer('gammas', torch.tensor([gamma**k for k in range(1, window_size+1)]))
    
    def forward(self, current_state, trajectory_history):
        """
        çª—å£åŒ–æ¼”åŒ–å…¬å¼:
        MRAO*(Î¨_t) = Î¨_t + âˆ‘_{k=1}^{W} Î³^k Â· (Î¨_{t-k} - Î¨_{t-k-1})
        """
        batch_size = current_state.shape[0]
        
        # ç¡®ä¿å†å²è½¨è¿¹é•¿åº¦è¶³å¤Ÿ
        if len(trajectory_history) < self.window_size + 1:
            # å¦‚æœå†å²ä¸å¤Ÿé•¿ï¼Œåªä½¿ç”¨å¯ç”¨çš„å†å²
            available_window = len(trajectory_history) - 1
            if available_window <= 0:
                return current_state
            
            # åªä½¿ç”¨å¯ç”¨çš„è½¨è¿¹
            gammas = self.gammas[:available_window]
            window_sum = torch.zeros_like(current_state)
            
            for k in range(available_window):
                if k+1 < len(trajectory_history):
                    diff = trajectory_history[-(k+1)] - trajectory_history[-(k+2)]
                    window_sum += gammas[k] * diff
            
            return current_state + window_sum
        
        # å®Œæ•´çª—å£
        window_sum = torch.zeros_like(current_state)
        for k in range(self.window_size):
            diff = trajectory_history[-(k+1)] - trajectory_history[-(k+2)]
            window_sum += self.gammas[k] * diff
        
        return current_state + window_sum

class StructurePreferenceScorer(nn.Module):
    """ç»“æ„åå¥½æ‰“åˆ†å‡½æ•°: ğ“›_pref"""
    
    def __init__(self):
        super().__init__()
    
    def forward(self, trajectory):
        """
        å®šä¹‰:
        ğ“›_pref(ğ“£) = (1/|ğ“£|) âˆ‘_t Var(Î¨_t)
        è¯„ä¼°ç»“æ„è½¨è¿¹åœ¨æ¼”åŒ–è¿‡ç¨‹ä¸­çš„ç†µæ¿€æ´»å¯†åº¦ä¸ç¨³å®šæ€§
        """
        if not trajectory:
            return torch.tensor(0.0)
        
        variances = [torch.var(state) for state in trajectory]
        mean_variance = sum(variances) / len(variances)
        return mean_variance

class ControlTensorGenerator(nn.Module):
    """æ§åˆ¶å¼ é‡ç”Ÿæˆå™¨: ğ“£_ctrl"""
    
    def __init__(self, control_dim=64, output_dim=768):
        super().__init__()
        self.mapping = nn.Linear(control_dim, output_dim)
    
    def forward(self, z):
        """
        å®šä¹‰æ§åˆ¶ä¿¡å·ç©ºé—´:
        z âˆˆ â„^k, ğ“£_ctrl(z) = Ïƒ(Wz) âˆˆ ğ”¾
        """
        return torch.sigmoid(self.mapping(z))

class SRCO(nn.Module):
    """ç»“æ„åæ¼”è®¡ç®—ç®—å­: SRCO"""
    
    def __init__(self, dim=768):
        super().__init__()
        self.self_attn = nn.MultiheadAttention(dim, num_heads=8)
        self.norm1 = nn.LayerNorm(dim)
        self.feed_forward = nn.Sequential(
            nn.Linear(dim, dim*4),
            nn.GELU(),
            nn.Linear(dim*4, dim)
        )
        self.norm2 = nn.LayerNorm(dim)
    
    def forward(self, x):
        # è‡ªæ³¨æ„åŠ›æœºåˆ¶
        attn_output, _ = self.self_attn(x, x, x)
        x = self.norm1(x + attn_output)
        
        # å‰é¦ˆç½‘ç»œ
        ff_output = self.feed_forward(x)
        x = self.norm2(x + ff_output)
        
        return x

class QCDAO(nn.Module):
    """é‡å­ç»å…¸åŒé‡ç®—å­: QCDAO"""
    
    def __init__(self, dim=768):
        super().__init__()
        self.quantum_proj = nn.Linear(dim, dim)
        self.classical_proj = nn.Linear(dim, dim)
        self.merge = nn.Linear(dim*2, dim)
    
    def forward(self, state):
        quantum_component = self.quantum_proj(state)
        classical_component = self.classical_proj(state)
        
        # é‡å­å åŠ 
        quantum_component = F.gelu(quantum_component)
        
        # ç»å…¸æŠ•å½±
        classical_component = torch.tanh(classical_component)
        
        # åˆå¹¶
        merged = torch.cat([quantum_component, classical_component], dim=-1)
        return self.merge(merged)

class QCITModel(nn.Module):
    """é‡å­ç»å…¸åŒæ„å˜æ¢å™¨: QCIT+"""
    
    def __init__(self, dim=768, control_dim=64, window_size=5):
        super().__init__()
        self.dim = dim
        
        # åˆå§‹åŒ–æ‰€æœ‰å­æ¨¡å—
        self.B_init = ClassicStateInitializer(output_dim=dim)
        self.H = ModalBridgeEncoder(dim=dim)
        self.SRCO = SRCO(dim=dim)
        self.MRAO = ExtendedMRAO(dim=dim, window_size=window_size)
        self.QCDAO = QCDAO(dim=dim)
        self.L_pref = StructurePreferenceScorer()
        self.T_ctrl = ControlTensorGenerator(control_dim=control_dim, output_dim=dim)
        
        # è½¨è¿¹å†å²
        self.trajectory_history = []
        
        # æ˜ å°„å¤´
        self.output_head = nn.Linear(dim, dim)
    
    def forward(self, x, modality='text', control_signal=None, initialize=True):
        """
        æœ€ç»ˆæ›´æ–°åçš„æ¼”åŒ–ä¸»å¾‹ï¼ˆç»“æ„åé¦ˆ + æ§åˆ¶ï¼‰:
        Î¨_{t+1} = SRCO(Î¨_t) + MRAO*(ğ“£_{0:t}) + ğ”¾_t
        """
        if initialize:
            # ä½¿ç”¨é€‚å½“çš„åˆå§‹åŒ–å™¨
            if modality == 'text':
                state = self.B_init(x['input_ids'], x.get('attention_mask'))
            else:
                state = self.H(x, modality)
            
            # é‡ç½®è½¨è¿¹å†å²
            self.trajectory_history = [state.detach()]
        else:
            # ä½¿ç”¨æœ€è¿‘çš„çŠ¶æ€
            state = self.trajectory_history[-1]
        
        # åº”ç”¨SRCO
        state = self.SRCO(state)
        
        # åº”ç”¨æ‰©å±•MRAOï¼ˆè€ƒè™‘è½¨è¿¹å†å²ï¼‰
        if len(self.trajectory_history) > 1:
            state = self.MRAO(state, self.trajectory_history)
        
        # åº”ç”¨æ§åˆ¶å¼ é‡ï¼ˆå¦‚æœæä¾›ï¼‰
        if control_signal is not None:
            G_t = self.T_ctrl(control_signal)
            state = state + G_t
        
        # åº”ç”¨QCDAO
        state = self.QCDAO(state)
        
        # æ›´æ–°è½¨è¿¹å†å²
        self.trajectory_history.append(state.detach())
        
        # å¦‚æœå†å²è¿‡é•¿ï¼Œä¿æŒå›ºå®šé•¿åº¦
        max_history = 50  # åˆç†çš„å†å²é•¿åº¦ä¸Šé™
        if len(self.trajectory_history) > max_history:
            self.trajectory_history = self.trajectory_history[-max_history:]
        
        # è®¡ç®—åå¥½åˆ†æ•°ï¼ˆä»…ç”¨äºç›‘æ§ï¼‰
        pref_score = self.L_pref(self.trajectory_history)
        
        # è¾“å‡ºæœ€ç»ˆçŠ¶æ€
        output = self.output_head(state)
        
        return output, pref_score
    
    def evolve_trajectory(self, steps=10, control_signals=None):
        """
        æ²¿ç€è½¨è¿¹æ¼”åŒ–æŒ‡å®šçš„æ­¥æ•°
        """
        if not self.trajectory_history:
            raise ValueError("éœ€è¦å…ˆåˆå§‹åŒ–è½¨è¿¹")
        
        outputs = []
        scores = []
        
        for i in range(steps):
            control_signal = None
            if control_signals is not None and i < len(control_signals):
                control_signal = control_signals[i]
            
            output, score = self.forward(None, initialize=False, control_signal=control_signal)
            outputs.append(output)
            scores.append(score)
        
        return outputs, scores 